{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en_core_web_sm')\n",
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\n",
      "and\n",
      "sentence\n",
      "tokenization\n",
      "can\n",
      "be\n",
      "done\n",
      "easily\n",
      "using\n",
      "the\n",
      "spacy\n",
      "library\n",
      "in\n",
      "python\n",
      ".\n",
      "In\n",
      "this\n",
      "NLP\n",
      "tutorial\n",
      ",\n",
      "we\n",
      "will\n",
      "cover\n",
      "tokenization\n",
      "and\n",
      "a\n",
      "few\n",
      "related\n",
      "topics\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Word and sentence tokenization can be done easily using the spacy library in python. In this NLP tutorial, we will cover tokenization and a few related topics.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "Let\n",
      "'s\n",
      "go\n",
      "to\n",
      "N.Y.\n",
      "!\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "# Tokenize concept\n",
    "doc = nlp('''\"Let's go to N.Y.!\"''')\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)\n",
    "type(doc)\n",
    "type(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Tony gave two $ to Dr. Strange.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tony"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token1 = doc[0]\n",
    "token1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token1.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2 = doc[2]\n",
    "token2.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It knws even with letter 'two', it is a number\n",
    "token2.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token3 = doc[3]\n",
    "token3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It knows it's a currency\n",
    "token3.is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony ===> index:  0 is_alpha - True is_punct - False like_num - False is_currency - False\n",
      "gave ===> index:  1 is_alpha - True is_punct - False like_num - False is_currency - False\n",
      "two ===> index:  2 is_alpha - True is_punct - False like_num - True is_currency - False\n",
      "$ ===> index:  3 is_alpha - False is_punct - False like_num - False is_currency - True\n",
      "to ===> index:  4 is_alpha - True is_punct - False like_num - False is_currency - False\n",
      "Dr. ===> index:  5 is_alpha - False is_punct - False like_num - False is_currency - False\n",
      "Strange ===> index:  6 is_alpha - True is_punct - False like_num - False is_currency - False\n",
      ". ===> index:  7 is_alpha - False is_punct - True like_num - False is_currency - False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, \"===>\", \"index: \", token.i,\n",
    "          \"is_alpha -\", token.is_alpha,\n",
    "          \"is_punct -\", token.is_punct,\n",
    "          \"like_num -\", token.like_num,\n",
    "          \"is_currency -\", token.is_currency\n",
    "          )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
