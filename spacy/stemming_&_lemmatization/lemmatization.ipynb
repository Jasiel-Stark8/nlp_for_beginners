{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We  |  we  |  16064069575701507746\n",
      "all  |  all  |  13409319323822384369\n",
      "love  |  love  |  3702023516439754181\n",
      "apples  |  apple  |  8566208034543834098\n",
      "except  |  except  |  1855464178306270225\n",
      "Apple  |  Apple  |  6418411030699964375\n",
      ",  |  ,  |  2593208677638477497\n",
      "but  |  but  |  14560795576765492085\n",
      "it  |  it  |  10239237003504588839\n",
      "was  |  be  |  10382539506755952630\n",
      "all  |  all  |  13409319323822384369\n",
      "over  |  over  |  5456543204961066030\n",
      "when  |  when  |  15807309897752499399\n",
      "jimmy  |  jimmy  |  6090167774541911232\n",
      "apples  |  apple  |  8566208034543834098\n",
      "said  |  say  |  8685289367999165211\n",
      ":  |  :  |  11532473245541075862\n",
      "Feel  |  feel  |  5741770584995928333\n",
      "The  |  the  |  7425985699627899538\n",
      "AGI  |  AGI  |  2987563183578869780\n",
      "!  |  !  |  17494803046312582752\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"We all love apples except Apple, but it was all over when jimmy apples said: Feel The AGI!\")\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.lemma_, \" | \", token.lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As powerful as Lemmatization is, it isn't always accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro  ->  bro\n",
      "what  ->  what\n",
      "'s  ->  be\n",
      "up  ->  up\n",
      "!  ->  !\n",
      "I  ->  I\n",
      "spoke  ->  speak\n",
      "to  ->  to\n",
      "Sam  ->  Sam\n",
      ",  ->  ,\n",
      "but  ->  but\n",
      "bruh  ->  bruh\n",
      "was  ->  be\n",
      "n't  ->  not\n",
      "getting  ->  get\n",
      "it  ->  it\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Bro what's up! I spoke to Sam, but bruh wasn't getting it\")\n",
    "for token in doc:\n",
    "    print(token, \" -> \", token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can customize the pipeline 'attribute_ruler' \\\n",
    "We aren't using ORTH as we did in the customize_pipeline notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
