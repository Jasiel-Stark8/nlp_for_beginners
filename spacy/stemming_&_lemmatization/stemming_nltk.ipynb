{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy has no support function for stemming \\\n",
    "According to SpaCy, Lemmatization is sophisticated enough so they only stick to that. \\\n",
    "So in this notebook we will be using NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer # SnowballStemmer is another stemmer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object for the stemmer class\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\n",
    "    \"running\", \"jumps\", \"easily\", \"fairer\", \"quickest\",\n",
    "    \"singing\", \"sings\", \"sung\", \"unresponsive\", \"responsivity\",\n",
    "    \"democratization\", \"historical\", \"argumentative\", \"computational\",\n",
    "    \"happiness\", \"traditional\", \"connection\", \"explanation\", \"meaningful\",\n",
    "    \"berries\", \"cities\", \"babies\", \"studies\", \"goes\", \"lied\", \"dying\",\n",
    "    \"sitting\", \"scared\", \"reduction\", \"driving\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running -> run\n",
      "jumps -> jump\n",
      "easily -> easili\n",
      "fairer -> fairer\n",
      "quickest -> quickest\n",
      "singing -> sing\n",
      "sings -> sing\n",
      "sung -> sung\n",
      "unresponsive -> unrespons\n",
      "responsivity -> respons\n",
      "democratization -> democrat\n",
      "historical -> histor\n",
      "argumentative -> argument\n",
      "computational -> comput\n",
      "happiness -> happi\n",
      "traditional -> tradit\n",
      "connection -> connect\n",
      "explanation -> explan\n",
      "meaningful -> meaning\n",
      "berries -> berri\n",
      "cities -> citi\n",
      "babies -> babi\n",
      "studies -> studi\n",
      "goes -> goe\n",
      "lied -> lie\n",
      "dying -> die\n",
      "sitting -> sit\n",
      "scared -> scare\n",
      "reduction -> reduct\n",
      "driving -> drive\n"
     ]
    }
   ],
   "source": [
    "for word, stemmed in zip(words, stemmed_words):\n",
    "    print(f\"{word} -> {stemmed}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
